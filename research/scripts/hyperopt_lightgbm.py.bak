STUDY_NAME = "lgb_tune"
STORAGE    = "sqlite:///optuna_trials.db"
STUDY_NAME = "lgb_tune"
STORAGE     = "sqlite:///optuna_trials.db"
#!/usr/bin/env python3
"""
Optuna tuner for the daily-bar LightGBM model.

Run:  python Research/scripts/hyperopt_lightgbm.py --trials 75
"""

import argparse, datetime as dt, joblib, optuna
from pathlib import Path
import lightgbm as lgb

from train_lightgbm import fetch_data, build_features


# ── helpers ────────────────────────────────────────────────────────────────
def _split() -> tuple[lgb.Dataset, lgb.Dataset]:
    try:
        df = build_features(fetch_data())
    except Exception as e:
        print("Data fetch failed:", e)
        raise optuna.TrialPruned()
    cut = int(len(df) * 0.7)
    X, y = df[["ret_5d", "vol_30d", "mom_20d", "mom_120d", "atr_14d", "skew_30d"]].values, df["target"].values
    return (
        lgb.Dataset(X[:cut],  label=y[:cut]),
        lgb.Dataset(X[cut:], label=y[cut:]),
    )


def _objective(trial: optuna.trial.Trial) -> float:
    dtrain, dvalid = _split()
    params = {
        "objective":     "binary",
        "metric":        "auc",
        "learning_rate": trial.suggest_float("lr", 0.01, 0.2, log=True),
        "num_leaves":    trial.suggest_int("nl", 15, 127),
        "min_child_samples": trial.suggest_int("mcs", 5, 50),
    "feature_fraction":  trial.suggest_float("ff", 0.5, 1.0),
    "bagging_fraction":  trial.suggest_float("bf", 0.5, 1.0),
    "lambda_l1":        trial.suggest_float("l1", 0.0, 5.0),
    "lambda_l2":        trial.suggest_float("l2", 0.0, 5.0),        "verbose":       -1,
    }
    booster = lgb.train(
        params,
        dtrain,
        num_boost_round=500,
        valid_sets=[dvalid],
        callbacks=[lgb.early_stopping(50, verbose=False)],
    )
    return booster.best_score["valid_0"]["auc"]


def main(trials: int) -> None:
    study = optuna.create_study(load_if_exists=True, study_name=STUDY_NAME, storage=STORAGE, direction="maximize")
    study.optimize(_objective, n_trials=trials, n_jobs=8)
    print("Best params:", study.best_params)
    print("Best  AUC  :", study.best_value)

    # retrain on full set with best params
    try:
        df = build_features(fetch_data())
    except Exception as e:
        print("Data fetch failed:", e)
        raise optuna.TrialPruned()
    FEATURES=["ret_5d","vol_30d","mom_20d","mom_120d","atr_14d","skew_30d"]
    dtrain = lgb.Dataset(df[["ret_5d", "vol_30d", "mom_20d", "mom_120d", "atr_14d", "skew_30d"]].values, label=df["target"].values)
    best = study.best_params | {"objective": "binary", "metric": "auc", "verbose": -1}
    booster = lgb.train(best, dtrain, num_boost_round=600)

    out = Path(__file__).resolve().parent.parent / "models"
    out.mkdir(exist_ok=True)
    fname = out / f"lgb_spy_optuna_{dt.date.today():%Y-%m-%d}.pkl"
    joblib.dump(booster, fname)
    Path("latest_auc.txt").write_text(str(study.best_value))
    print("Model saved →", fname)


if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--trials", type=int, default=50)
    main(p.parse_args().trials)
